{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial #4 - Analyze data\n",
    "Welcome to Cognitive Class Labs. This notebook is the **fourth** in a series of \"getting started\" tutorials that is designed to introduce some basic concepts and help get you familiar with using the workbench.\n",
    "\n",
    "In this notebook we introduce you to the search feature and perform some analysis on our winter medal data set.  Specifically, this tutorial covers:\n",
    "\n",
    "1. How to use sidebar to find previous work\n",
    "1. Analysis: Predicting medal counts\n",
    "    * Probability distribution\n",
    "    * Bayesian inference\n",
    "    * Results\n",
    "\n",
    "## Pre-requisites\n",
    "Though not required, it is recommended that you complete the other tutorials as well before proceeding. You can eiher download previous tutorial notebooks from the [Welcome](/pages/welcome) page or use Sidebar to find them. \n",
    "\n",
    "## Sidebar: How to find previous work?\n",
    "In a previous tutorial notebook in this getting started series, you loaded the olympic medal data set and calculated and plotted the total medals that Norway had been awarded at each olympic games from 1924 through 2006.\n",
    "\n",
    "Do you remember the lines of code we used to do this?  For that matter, do you remember which notebook the code is in?\n",
    "\n",
    "Once you have created even just a few notebooks, remembering what you did and in which notebook is a common problem (at least for the IBM Data Scientist team, it is).  This is why the Data Scientist Workbench includes the ability to search notebooks.\n",
    "\n",
    "You can use the search feature to find and reproduce the Norway medal plot.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">**Note:** Search matches against the following\n",
    "<ol>\n",
    "<li>File names and paths (all types)</li>\n",
    "<li>File tags (all types)</li>\n",
    "<li>Notebook content (source cells only)</li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "For example, if you want to find the notebook where you loaded the medals data, and look at the lines of code into this notebook. \n",
    "\n",
    "1. In the search bar, enter the text `read_csv`.  You should see a new \"Search - read_csv\" view containing a list of search hits.  Among the hits should be *this* notebook (because it contains the search term), **Tutorial #2 - Explore and Visualize**, and perhaps others.\n",
    "2. In the \"Search - read_csv\" view, open the **Tutorial #2 - Explore and Visualize** notebook by clicking its link.\n",
    "\n",
    "\n",
    "### Load Medals Data\n",
    "If you have not loaded the medals data before, you can load it by taking\n",
    "following steps:\n",
    "\n",
    "1. Download the olympic medal data in CSV format.  Click this [Box link](https://ibm.box.com/s/8u9yc1hj7ddvptablj312asm6sfgn5gw) to open the document in a new browser window. \n",
    "1. Save the CSV file to your computer by clicking on the Download button.\n",
    "1. Drag the CSV file from your desktop onto the workbench (Note that the CSV file appears under your **Recent Data** panel in the sidebar.)\n",
    "1. Click the arrow button (**>**) next to the CSV file you just uploaded.\n",
    "1. In the section that appears below the item, click \"Rename\"\n",
    "1. Change the name of the file to \"medals.csv\" and press Enter or click outside the name.\n",
    "1. Execute the code cell by clicking the (**&#9658;**) play button on the notebook toolbar, or by pressing Ctrl-Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "medals_df = pandas.read_csv('/resources/medals.csv')\n",
    "# Prune non-data rows\n",
    "medals_df = medals_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Medal Count per Year (Norway)\n",
    "Same as **Tutorial #2 - Explore and Visualize** notebook, we plot the model count for Norway. You can find the notebook where you plotted the medal count for Norway for all winter olympic games. \n",
    "\n",
    "1. In the search bar, enter the text `nor_medals_year`.  You should see a new \"Search - nor_medals_year\" view containing a list of search hits. \n",
    "2. In the \"Search - nor_medals_year\" view, open the **Tutorial #2 - Explore and Visualize** notebook by clicking its link.\n",
    "3. Locate the code cells that contain `nor_medals_year` and copy and paste their contents in the code cell below.  There should be a line of code to calculate the medal counts, and one to plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tell the notebook to render charts inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nor_medals_year = medals_df[medals_df.NOC == 'NOR'].groupby('Year').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Probable Medal Count\n",
    "In the **Tutorial #2 - Explore and Visualize** notebook, you determined that Norway had won the most combined medals - *in every color* - of any country from 1924 through 2006.  Clearly, Norway is a winter olympic juggernaut.\n",
    "\n",
    "If it were January 2010, and you had a Norwegian friend that insisted that you answer the question, \"How many medals do you think Norway will win in this year's olympics?\", what would you tell her?  What if she asked you the same question in January 1988 (you've been friends a long time).  Would you give her the same answer?\n",
    "\n",
    "Looking at the medal count per games for Norway, you notice that *something* changed circa 1992, and Norwegian olympians began to win more medals in every winter olympics since then.  You would not likely have given Norway much chance at all to win 20 medals in 1988, but in 2010, the chances that Norway would win 20 medals seems a good bit higher.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">The following example and code is based on the text message example that can be found in <a href=\"http://nbviewer.ipython.org/github/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/blob/6f3a973657b0d3f92bea63b154eadd1590b98e1e/Chapter1_Introduction/Chapter1.ipynb\">Probabilistic Programming and Bayesian Methods for Hackers, Chapter 1</a>.</div>\n",
    "\n",
    "### Probability Distribution\n",
    "You like stats, so you decide to provide your friend with a [probability distribution](http://en.wikipedia.org/wiki/Probability_distribution) for Norway's medal counts.\n",
    "\n",
    "You let M be the medal count awarded to a country during an olympic games competition. You assume that M is a random variable (there are, after all, many things that may affect the outcome of an olympic competition).  You further assume that there exists a function that gives the probability that each medal count occurs.  Because medal count is discrete (0, 1, 2, 3, and so on - you cannot win 11.42 medals), this function is known as a [probability mass function](http://en.wikipedia.org/wiki/Probability_mass_function).\n",
    "\n",
    "You assume that the probability mass function that governs medal count follows a [Poisson distribution](http://en.wikipedia.org/wiki/Poisson_distribution).  That is, the probability of the medal count M is equal to the number of medals n is governed by the equation:\n",
    "\n",
    "$$P(M = n) =\\frac{ \\lambda^n e^{-\\lambda} }{n!}, \\; \\; n=0,1,2, \\dots $$\n",
    "\n",
    "From the equation, you can see the probability is dependent on $\\lambda$.  $\\lambda$ is what you need to find to produce the medal count probability distribution for your Norwegian friend.\n",
    "\n",
    "The value of $\\lambda$ determines the shape of the probability distribution.  Two very different $\\lambda$s will produce two very different distributions.  To illustrate this, you can plot a Poisson distribution with two different values of $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.core.pylabtools import figsize\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['axes.facecolor'] = '#F5F5F5'\n",
    "\n",
    "figsize(11, 6)\n",
    "\n",
    "import scipy.stats as stats\n",
    "a = np.arange(30)\n",
    "poi = stats.poisson\n",
    "lambdas = [2.5, 14.5]\n",
    "colors = [\"#6B6A96\", \"#943A45\"]\n",
    "\n",
    "# plot a Poisson distribution for each lambda\n",
    "for lambda_, color in zip(lambdas, colors):\n",
    "    plt.bar(a, poi.pmf(a, lambda_), color=color,\n",
    "            label=\"$\\lambda = %.1f$\" % lambda_, alpha=0.50,\n",
    "            edgecolor=color, lw=1.5)\n",
    "\n",
    "plt.title(\"Probability mass function of a Poisson random variable\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.ylabel(\"probability of $n$\")\n",
    "plt.xticks(a + 0.4, a)\n",
    "plt.xlabel(\"$n$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretend this was the plot of our medal count distribution.  The lower value of $\\lambda$ = 2.5 would produce higher probabilities for lower medal counts (25% chance of winning 2 medals, but virtually no chance of winning 15 medals), whereas the higher $\\lambda$ = 14.5 would assign higher probabilities for higher medal counts (virtually no chance of winning 0 medals, but much greater chance of a medal count in the teens).\n",
    "\n",
    "So what is $\\lambda$ for Norway's medal count?  Well, from Norway's historical medal count plot, you observed that something changed in 1992, so you suspect that Norway's historical medal count is actually governed by *two* different values of $\\lambda$: the $\\lambda_1$ pre-1992 olympics, and the $\\lambda_2$ post-1992 olympics.  In other words,\n",
    "\n",
    "$$\n",
    "\\lambda = \n",
    "\\begin{cases}\n",
    "\\lambda_1  & \\text{if } t \\lt \\tau \\cr\n",
    "\\lambda_2 & \\text{if } t \\ge \\tau\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\tau$ is the switchpoint.  (You observe that $\\tau$ appears to be the 1992 olympic games, but you're going to let the math prove it).\n",
    "\n",
    "### Bayesian Inference\n",
    "You're a fan of using Bayesian statistics, when it makes sense, and you think this may be one of those times.  [Bayesian inference](http://en.wikipedia.org/wiki/Bayesian_inference) attempts to derive *posterior probabilities* from *prior probabilities* and a *likelihood function*.  In plain English, you want to predict 2010 medal count probabilities from historical medal count probabilities and a model representing how likely the new probabilities are to occur.\n",
    "\n",
    "Without getting bogged down in the details, you need to create:\n",
    "\n",
    "1. prior probabilities of medal counts\n",
    "1. a model (comprised of $\\tau$, $\\lambda_1$, and $\\lambda_2$) that represents the likelihood of the posterior probabilities\n",
    "\n",
    "To do all this, you install [`PyMC`](http://pymc-devs.github.io/pymc/), a Python library for performing Bayesian analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pip install pymc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You use the code below to create a model using the prior Norway medal counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "\n",
    "def make_model(data):\n",
    "    '''\n",
    "    Create a model for use in predicting lambda_1, lambda_2, and tau,\n",
    "    which combine to create our posterior probability distributions\n",
    "    (one before tau, and one after tau).\n",
    "    '''\n",
    "    # prior lambda estimates\n",
    "    alpha = 1.0 / data.mean() \n",
    "    lambda_1 = pm.Exponential(\"lambda_1\", alpha)\n",
    "    lambda_2 = pm.Exponential(\"lambda_2\", alpha)\n",
    "    # prior tau estimates\n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=len(data))\n",
    "\n",
    "    @pm.deterministic\n",
    "    def lambda_(tau=tau, lambda_1=lambda_1, lambda_2=lambda_2):\n",
    "        '''Create random value of lambda, based on prior lambda.'''\n",
    "        out = np.zeros(len(data))\n",
    "        out[:tau] = lambda_1  # lambda before tau\n",
    "        out[tau:] = lambda_2  # lambda after (and including) tau\n",
    "        return out\n",
    "    \n",
    "    # lambda is Poisson distributed\n",
    "    observation = pm.Poisson(\"obs\", lambda_, value=data.values, observed=True)\n",
    "\n",
    "    model = pm.Model([observation, lambda_1, lambda_2, tau])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = make_model(nor_medals_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to use PyMC's [Markov chain Monte Carlo](http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo) (MCMC) object to sample thousands of random possibilities of $\\lambda_1$, $\\lambda_2$, and $\\tau$, and collect samples (also random) of posterior values of each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mcmc = pm.MCMC(model)\n",
    "mcmc.sample(50000, 10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the PyMC MCMC algorithm is called a *trace*, which is the sequence of retained samples for each variable in the model.  Here you extract the last set of samples for each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lambda_1_samples = mcmc.trace('lambda_1')[:]\n",
    "lambda_2_samples = mcmc.trace('lambda_2')[:]\n",
    "tau_samples = mcmc.trace('tau')[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now plot the samples to give us the posterior probabilities of $\\lambda_1$, $\\lambda_2$, $\\tau$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# our data\n",
    "data = nor_medals_year\n",
    "n_data = len(data)\n",
    "years = data.index.values\n",
    "\n",
    "figsize(10, 12)\n",
    "xticks = np.arange(0, 31, 1)\n",
    "yticks = np.arange(0.0, 1.1, 0.1)\n",
    "\n",
    "# lambda_1\n",
    "ax = plt.subplot(311)\n",
    "ax.set_autoscaley_on(False)\n",
    "plt.hist(lambda_1_samples, histtype='stepfilled', bins=30, alpha=0.65,\n",
    "         label=\"Posterior of $\\lambda_1$\", color=\"#6B6A96\", normed=True)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(xticks)\n",
    "plt.yticks(yticks)\n",
    "plt.xlabel(\"$\\lambda_1$ value\")\n",
    "plt.ylabel(\"probability\");\n",
    "plt.title(r\"\"\"Posterior distributions of $\\lambda_1,\\;\\lambda_2,\\;\\tau$\"\"\")\n",
    "plt.grid()\n",
    "\n",
    "# lambda_2\n",
    "ax = plt.subplot(312)\n",
    "ax.set_autoscaley_on(False)\n",
    "plt.hist(lambda_2_samples, histtype='stepfilled', bins=30, alpha=0.65,\n",
    "         label=\"posterior of $\\lambda_2$\", color=\"#943A45\", normed=True)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(xticks)\n",
    "plt.xlim([xticks.min(), xticks.max()])\n",
    "plt.yticks(yticks)\n",
    "plt.xlabel(\"$\\lambda_2$ value\")\n",
    "plt.ylabel(\"probability\");\n",
    "plt.grid()\n",
    "\n",
    "# tau\n",
    "ax = plt.subplot(313)\n",
    "w = 1.0 / tau_samples.shape[0] * np.ones_like(tau_samples)\n",
    "plt.hist(tau_samples, bins=n_data, alpha=1,\n",
    "         label=r\"posterior of $\\tau$\",\n",
    "         color=\"#799631\", weights=w, rwidth=2.)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.xticks(np.arange(n_data), years, rotation='vertical')\n",
    "plt.yticks(yticks)\n",
    "plt.xlabel(r\"$\\tau$ (year of games)\")\n",
    "plt.ylabel(\"probability\");\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "Recall that $\\lambda_1$ defines the probability distribution before $\\tau$.  The first plot shows $\\lambda_1$ is about 11, and the probability that Norway wins 11 medals in the 1988 winter olympics would have been nearly 50%.  Further, the distribution of this plot is narrow, meaning there was low uncertainty in getting a medal count outside of the 9 to 13 range.  Unfortunately, if you based your prediction on these results, you would have been way off.  1988 was the first and only time Norway failed to win a gold medal in the winter olympics.  Norway took home a mere 5 medals. (It is important to note that the Poisson distribution is infinite.  That is, there was a probability, however small, of Norway winning 5 medals.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nor_medals_year['1988']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well would you have predicted the 2010 medal count?  Looking at the second plot, the value of $\\lambda_2$ is about 23. The uncertainty is greater, as indicated by the wider distribution, so the highest probability was about 20% (to win 23 medals).  There was a combined probability of about 50% to win either 22, 23, or 24 medals.  As it turns out, Norway won [23 medals](http://en.wikipedia.org/wiki/2010_Winter_Olympics_medal_table) in the 2010 winter olympics?  Nice work!\n",
    "\n",
    "What about $\\tau$?  Your model validated your earlier observation that something changed in the winter olympic games starting in 1992.  The third plot shows a greater than 90% chance of a change occurring that year.  If there was no change, and $\\lambda_1$ and $\\lambda_2$ turned out to be similar, then the two distributions would have looked the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Olympic Events\n",
    "So what changed in 1992?  That's easy to answer (at least partially).  The International Olympic Committee added more events and handed out more medals.  In fact, the number of events and medals has increased sharply since 1988.  Below is a plot showing the upward trend in both number of events and number of medals awarded in each winter games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot medals awarded per games\n",
    "ax = medals_df.groupby('Year').size()\\\n",
    ".plot(figsize=(10,5), legend=True, label='Medals')\n",
    "ax.set_ylabel('Medals')\n",
    "\n",
    "# plot events per games\n",
    "events_year = medals_df.drop_duplicates(subset=['Year','Sport','Discipline','Event'])\\\n",
    ".groupby('Year').size()\n",
    "events_year.plot(secondary_y=True, legend=True, label='Events', mark_right=False)\n",
    "ax.right_ax.set_ylabel('Events')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the curious, here are the events that have been added since 1988:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "events_2006 = set(medals_df[medals_df.Year == '2006']\\\n",
    ".groupby(['Sport','Discipline','Event'])\\\n",
    ".groups.keys())\n",
    "\n",
    "events_1988 = set(medals_df[medals_df.Year == '1988']\\\n",
    ".groupby(['Sport','Discipline','Event'])\\\n",
    ".groups.keys())\n",
    "\n",
    "new_events_since_1988 = events_2006 - events_1988\n",
    "new_events_since_1988"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the number of medals won by Norway in these events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def nor_medal_count(row):\n",
    "    return (row.Sport, row.Discipline, row.Event) \\\n",
    "        in new_events_since_1988 \\\n",
    "        and row.NOC == 'NOR'    \n",
    "nor_new_medals = medals_df.apply(nor_medal_count, axis=1)\n",
    "len(nor_new_medals[nor_new_medals == True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: Share and Reuse\n",
    "Our next tutorial topic will focus on how Cognitive Class Labs can help you share and reuse notebooks. Visit the [Welcome](/pages/welcome) page to download **Tutorial #5 - Share and Reuse**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by: <a href=\"https://bigdatauniversity.com/?utm_source=bducreatedbylink&utm_medium=dswb&utm_campaign=bdu\">The Cognitive Class Team</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
